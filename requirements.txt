# Corrected requirements.txt for QTinker App
# Core transformers and models
accelerate>=1.3.0
diffusers>=0.32.0
safetensors>=0.5.0

# Quantization and optimization
gguf>=0.17.0
bitsandbytes>=0.45.0

# Advanced Quantization (Post-training & QAT)
auto-gptq>=0.7.1
neural-speed==1.0  # Final stable release; project archived

# Pruning and Sparsity
# sparseml>=1.7.0 removed due to EOL June 2025 and build failures
# wanda-pruning is not a pip package; clone https://github.com/locuslab/wanda manually
datasets>=2.14.0
wandb
sentencepiece

# Distillation frameworks
sentence-transformers>=3.4.0

# ONNX optimization and conversion
onnx-simplifier>=0.4.36
skl2onnx>=1.18.0

# End-to-end model optimization pipeline
neural-compressor>=3.7.1

# Intel optimization for CPU inference
intel-extension-for-transformers>=1.3.0

# OpenVINO toolkit (model optimization and inference)
openvino>=2024.6.0

# UI and visualization
gradio>=4.0.0
pyyaml>=6.0.1
requests>=2.32.0

# Framework support
tensorflow>=2.18.0
tensorrt==10.9.0.34
jax>=0.5.0
jaxlib>=0.5.0

# Additional utilities
pillow>=11.0.0
opencv-python>=4.11.0
librosa>=0.10.2
scipy>=1.15.0

# ONNX support (optional, for model export)
onnx
onnxruntime>=1.20.0

# Quantization tools
llama-cpp-python>=0.3.5; sys_platform == 'linux' or sys_platform == 'darwin'

# Synthetic Data Pipeline and Distillation
data-designer==0.5.1
openai>=1.0.0
pydantic>=2.0.0
pandas>=1.5.0
jinja2>=3.0.0

# Local LLM Support
requests>=2.32.0
aiohttp>=3.8.0

# Dependencies for fairseq model loading
fairseq
sacrebleu
portalocker
